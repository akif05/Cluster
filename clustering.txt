## Clustering, Clastering, read from stdin
corosync on suse
First node: "node1"
	zypper in ha-cluster-bootstrap
	ha-cluster-inet

All other nodes
	zypper in ha-cluster-bootstrap
	ha-cluster-join -c node1

# Check status
	crm_mon
	systemctl status corosync
	
### Ha on redhad (centos)
yum -y install epel-release
yum -y install pcs fence-agents-all
firewall-cmd --permanent --add-serice=high-availablility 
systemctl enable --now pcsd
echo password | passwd --stdin hacluster

# Authenticate all nodes. Run the command on one node ONLY!
pcs cluster auth server1.example.com server2.example.com server3.example.com

Provide hacluster username and password, that was created

pcs cluster setup --start --name mycluster server1.example.com server2.example.com server3.example.com

After reboot node will not join the cluster automaticaly!
If you want to join automaticaly run:
	pcs cluster enable --all

# Verify cluster opearation
pcs cluster status
systemctl status pcsd
systemctl status corosync
systemctl status corosync -l



####### ssh tunnel
### Working all the 3 for loops !!!!!
for i in `seq 1 3`; do ipaddr=$(printf "192.168.4.2%d0\n" $i); echo $ipaddr; ssh root@$ipaddr 'yum -y install epel-release; \
					yum -y install pcs fence-agents-all; \
					firewall-cmd --permanent --add-serice=high-availablility; \ 
					firewall-cmd --reload; \ 
					systemctl enable --now pcsd; \
					echo password | passwd --stdin hacluster'
					done

#########################################################################
for i in `seq 1 3`; do ipaddr=$(printf "192.168.4.2%d0\n" $i); ssh root@$ipaddr 'awk "!/192.168.4/" /etc/hosts > temp && mv temp /etc/hosts <<< yes; \
			printf "192.168.4.210\tserver1.example.com\tserver1\n192.168.4.220\tserver2.example.com\tserver2\n192.168.4.230\tserver3.example.com\tserver3\n" >> /etc/hosts'
			done

for i in `seq 1 3`; do ipaddr=$(printf "192.168.4.2%d0\n" $i); ssh root@$ipaddr 'cat /etc/hosts'
			done

## Do not use this scripts in production!!!
## Delete the lines starting with 192.168... from the hosts file
for i in `seq 1 3`; do ipaddr=$(printf "192.168.4.2%d0\n" $i); echo $ipaddr; ssh root@$ipaddr 'awk "!/192.168*/" /etc/hosts > temp && mv temp /etc/hosts <<< yes'
			done
#########################################################################

############ Thise are test for loops!!! ################################
for i in `seq 1 3`; do echo $i; done
for i in `seq 1 3`; do printf "192.168.4.2%d0\n" $i; done
for i in `seq 1 3`; do ipaddr=$(printf "192.168.4.2%d0\n" $i); echo $ipaddr; done
for i in `seq 1 3`; do ipaddr=$(printf "192.168.4.2%d0\n" $i); echo $ipaddr; ssh root@$ipaddr 'ls /root'; done

for i in `seq 1 3`; do ipaddr=$(printf "192.168.4.2%d0\n" $i); ssh root@$ipaddr 'pcs resource create httpfs Filesystem device=/dev/sdc1 directory=/srv/www/htdocs fstype=ext4'; done



for i in `seq 1 3`; do ipaddr=$(printf "192.168.4.2%d0\n" $i); ssh root@$ipaddr 'pcs resource show httpsfs'; done




for i in `seq 1 3`; do ipaddr=$(printf "192.168.4.2%d0\n" $i); ssh root@$ipaddr 'mkdir -p /srv/www/htdocs'; done




top -I 
top.rc. 

top + f P
vmstat 2 20
/proc
and 
sysctl
# to tune parameter in kernel
# this is run time only
/proc/sys

# For persistent use sysctl
# write parameter in sysctl
# file path in /proc/sys, replace / with . for variable name
# list off all tunable
sysctl -a 

cd /proc/sys
kernel net and vm are most in use
vm == virtual memory.  = is address space:w

cd kernel

cat hostname
cat pid_max.   == this is availible pid, can be changed
cd ../vm
cat drop_caches.    = it is trigre value
free -m
cat 2 > drob_caches
# can free memmory

ssh ser1
virsh list

swapins == liklihood system to use swap, biger == sysetem is eager to use swap

# lover value to use less swap, start swaping when 

vi /etc/sysctl.conf
vm.swappiness = 60

sysctl --help

cd /usr/lib/sysctl.d
vi 60-libvirtd.conf

# installed progarms are using /usr/lib/sysctl.d

# System admin must use /etc...
cd /etc/sysctl.d/

echo 10 > swappiness

## keep your tunable settings.
vi /etc/sysctl.d/50-akif.conf


iotop

boni++
sar
## write 4GB of data test
# apply fiwe times
# important is sys time 
# real we can not tune, but only sys

time dd if=/dev/zero  of=/4Gfile bs=1M count=4096
real
user
sys  0m2.719s

ext4 is using
File system journaling (file system integrity)

Copy on write
man mount
To have quick file system
/data=writeback
kjurnald -- eating processor time implement ext4 with 
	/data=writeback

ioscheduler

cd /sys/
cd block/sda
cd queue
This queue is used to
cat scheduler
noop [deadline] cfq
# in bracket is active value

# Extend writing data to disk
noop is giving worse performance
noop == nooperation (use in vm, or sotrage is on san) 
complete fair queueng == cfq

echo noop > shceduler
pwd
/sys/block/sda/queue

cgroups is resource limitation

¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡
man 5 systemd resource control

Linux performance leson
free -m
cd /proc/sys/vm
cat nr_hugepages
free -m
echo 200 > nr_hugepages
free -m
echo h > /proc/sysrq-triger
echo f > /proc/sysrq-triger
cd /proc/sys
cd vm
ls | grep panic
panic_on_oom

cat panic_on_oom
echo 1 > panic_on_om
echo f > /proc/sysrq-triger

velgraing memory leack issue


# network performans
ip -s link
qperf

## Statistic about network performance
qperf server1 tcp_bw tcp_lat
nc -l 2345 > bigfile on serfver1
time cat bigfile | nc 

rpm -pa | grep sysstat
cat /etc/cron.d/sysstat
ls /var/log/sa
sar -b
sar -C
sar -P ALL

man sar

sar usefull example.

Linux fundation 



